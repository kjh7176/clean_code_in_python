# 3. General Traits of Good Code

## 3-1. Design by contract
The idea behind DbC is that instead of implicitly placing in the code what every party is expecting, both parties agree on a contract that, if violated, will raise an exception, clearly stating why it cannot continue.  
In our context, a **contract** is a construction that enforces some rules that must be honored during the communication of software components.  
- Preconditions: all the checks code will do before running (in the code)
- Postconditions: the validations done after the function call is returned (in the code)
- Invariants: the tings that are kept constant while the code of the function is running (in the docstring)
- Side-effects: side-effects of our code (in the docstring)

## 3-2. Defensive programming
Defensive programming is about making all parts of the code able to protect themselves against invalid inputs.
- Error handling: how to handle errors for scenarios that we might expect to occur
- Assertions: how to deal with errors that should never occur

### (1) Error handling
The idea behind error handling is to gracefully respond to these expected errors in an attempt to either continue our program execution or decide to fail if the error turns out to be insurmountable.  
- Value substitution  
In some scenarios, when there is an error and there is a risk of the software producing an incorrect value or failing entirely, we might be able to replace the result with another, safer value.  
Making this decision is a trade-off between robustness and correctness.  
If the application is critical, or the data being handled is too sensitive, this is not an option.

- Error logging
- Exception handling  
When a fault in a function call is due to a problem on one of these external components, then function should clearly and unambiguously notify the rest of the application about errors that cannot be ignored so that they can be addressed accordingly.  
    - Handle exceptions at the right level of abstraction  
    The exception the function is handling has to be consistent with the logic encapsulated on it.  
    ex1-1) an object handling exceptions of different levels
    ```
    class DataTransport:
        """An example of an object handling exceptions of different levels."""

        retry_threshold: int = 5
        retry_n_times: int = 3

        def __init__(self, connector):
            self._connector = connector
            self.connection = None

        def deliver_event(self, event):
            try:
                self.connect()
                data = event.decode()
                self.send(data)
            except ConnectionError as e:
                logger.info("connection error detected: %s", e)
                raise
            except ValueError as e:
                logger.error("%r contains incorrect data: %s", event, e)
                raise

        def connect(self):
            for _ in range(self, retry_n_times):
                try:
                    self.connection = self._connector.connect()
                except Connectionerror as e:
                    logger.info(
                        "%s: attempting new connection in %is",
                        e,
                        self.retry_threshold,
                    )
                    time.sleep(self.retry_threshold)
                else:
                    return self.connection
            raise ConnectionError(
                f"Couldn't connect after {self.retry_n_times} times"
            )

        def send(self, data):
            return self.connection.send(data)
    ```
    The `ConnectionError` should be handled inside the `connect` method.  
    The `ValueError` belongs to the `send` method of the event.  
    We should seperate these fragments into different methods or functions.  

    ex1-2) connection management
    ```
    def connect_with_retry(connector, retry_n_times, retry_threshold=5):
        """Tries to establish the connection of <connector> retrying
        <retry_n_times>.

        If it can connect, returns the connection object.
        If it's not possible after the retries, raises ConnectionError.

        :param connector: An object with a `.connect()` method.
        :param retry_n_times int: The number of times to try to call
            `connector.connect()`.
        :param retry_threshold int: The time lapse between retry calls.
        """

        for _ in range(retry_n_times):
            try:
                return connector.connect()
            except ConnectionError as e:
                logger.info(
                    "%s: attempting new connection in %is",
                    e,
                    retry_threshold
            )
            time.sleep(retry_threshold)
        exc = ConnectionError(f"Couldn't connect after {retry_n_times} times)
        logger.exception(exc)
        raise exc
    ```

    ex1-3) the new version of ex1-1
    ```
    class DataTransport:
        """An example of an object that separates the exception handling by
        abstraction levels.
        """

        retry_threshold: int = 5
        retry_n_times: int = 3

        def __init__(self, connector):
            self._connector = connector
            self.connection = None

        def deliver_event(self, event):
            self.connection = connect_with_retry(
                self._connector, self.retry_n_times, self.retry_threshold
            )
            self.send(event)

        def send(self, event):
            try:
                return self.connection.send(event.decode())
            except ValueError as e:
                logger.error("%r contains incorrect data: %s", event, e)
                raise
    ```
    - Do not expose tracebacks
    In python, tracebacks of exceptions contain very rich and useful debugging information.  
    Unfortunately, this information is also very useful for attackers or malicious users who want to try and harm the application.  
    If you have to notify users about a problem, choose generic messages.

    - Avoid empty except blocks
    The problem with this is that it will not fail even when it should.  
    We need to know if there is an error in our logic to be able to correct it.  
    Instead, catch a more specific exception and do some actual error handling on the except block.  
    When it comes to logging the exception, make sure to use `logger.exception` or `logger.error` to provide the full context of what happened.

    - Include the original exception
    Always use the `raise <e> from <o>` syntax when changing the type of the exception.  
    When using this construction, the original traceback will be embedded into the new exception, and the original exception will be set in the `__cause__` attribute of the resulting one.
    ex2) custom exception
    ```
    def process(data_dictionary, record_id):
        try:
            return data_dictionary[record_id]
        except KeyError as e:
            raise InternalDataError("Record not present") from e
    ```

### (2) Using assertions in Python
Assertions are to be used for situations that should never happen.  
The idea of using assertions is to prevent the program from causing further damage if such an invalid scenario is presented.  
Do not catch the `AssertionError` eception and make sure that the program terminates when an assertion fails.  
ex1-1) bad usage of assertions
```
try:
    assert condition.holds(), "Condition is not satisfied"
except AssertionError:
    alternative_procedure()
```
ex1-2) more useful usage
```
result = condition.holds()
assert result > 0, "Error with {0}".format(result)
```

## 3-3. Separation of concerns
The coal of separating concerns in software is to enhance maintainability by minimizing ripple effects.  
A ripple effect means the propagation of a change in the software from a starting point.  
### (1) Cohesion and coupling
Well-defined software will achieve high cohesion and low coupling.  
- Cohesion: objects should have a mall and well-defined purpose, and they should do as little as possible
- Coupling: how two or more objects depend on each other

## 3-4. Acronyms to live by
### (1) DRY/OAOO
> Don't Repeat Yourself  
One and Only Once  

You should avoid duplication at all costs.  
When you have to make a change in the code, there should be only one rightful location to modify.  

### (2) YAGNI
> You Ain't Gonna Need It

Having maintainable software is not about anticipating future requirements.  
It is about writing software that only addresses current requirements in such a way that it will be possible to change later on.  
When designing, make sure that your decisions don't tie you down, and that you will be able to keep on building, but do not build more than what's necessary.  

### (3) KIS
> Keep It Simple

When you are designing a software component, avoid over-engineering it; ask yourself if your solution is the minimal one that fits the problem.

### (4) EAFP/LBYL
>Easier to Ask Forgiveness than Permission
Look Before You Leap

EAFP is the opposit eof LBYL.  
Python was built with ideas such as EAFT, and it encourages you to follow them.  
ex1-1) LBYL
```
if os.path.exists(filename):
    with open(filename) as f:
        ...
```
ex1-2) EAFP
```
try:
    with open(filename) as f:
        ...
except FileNotFoundError as e:
    logger.error(e)
```

## 3-5. Composition and inheritance
Probably the most commonly used of object-oriented software design ideas is inheritance.  
While we should always embrace code reuse, it is not a good idea to force our design to use inheritance to reuse code just because we get the methods from the parent class for free.  
The proper way to reuse code is to have highly cohesive objects that can be easily composed and that could work on multiple contexts.  

### (1) When inheritance is a good decision
When creating a new subclass, we have to think if it is actually going to use all of the methods it has just inherited.  
A good case for using inheritance:
- when you have a class that defines certain components with its behavior that are **defined by the interface of this class** (its public methods and attributes), and then you need to specialize this class in order to create objects that **do the same but with something else added, or with some particular parts of its behavior changed**.  
- when we want to **enforce the interface** of some objects, we can create **an abstract base class** that does not implement the behavior itself, but instead just defines the interface-**every class that extends this one will have to implement** these to be a proper subtype.
- exceptions; We can see that the standard exception in Python derives from `Exception`.  

### (2) Anti-patterns for inheritance
The correct use for inheritance is to specialize objects and create more detailed abstractions starting from base ones.  
When we read the public methods of a class, they have to be consistent with what the parent class defines.  
ex1-1) an incorrect use of inheritance
```
class TransactionalPolicy(collections.UserDict):
    def change_in_policy(self, customer_id, **new_policy_data):
        self[customer_id].update(**new_policy_data)
```
```
>>> policy = TransactinoalPolicy({
        "client001": {
            "fee": 1000.0,
            "expiration_date": datetime(2020, 1, 3),
        }
    })
>>> policy["client001"]
{'fee': 1000.0, 'expiration_date': datetime.datetime(2020, 1, 3, 0, 0)}
>>> policy.change_in_policy("client001", expiration_date=datetime(2020, 1, 4))
>>> policy["client001"]
{'fee': 1000.0, 'expiration_date': datetime.datetime(2020, 1, 4, 0, 0)}
```
```
>>> dir(policy)
[ # all magic and speial method have been omitted for brevity...
`change_in_policy`, 'clear', 'copy', 'data', 'fromkeys', 'get', 'items', 'keys',
'pop', 'popitem', 'setdefault', 'update', 'values']
```
- `TransactionalPolicy` class is not a more specific version of `collections.UserDict`.
- This is part of the public interface of the object, so users will see this class, their hierarchy as well as its public methods.
- `TransactionalPolicy` includes all methods from a dictionary that's even unnecessary.
- The only method it actually needs, `change_in_policy()`, is not on the base class.  

ex1-2) refactored to use composition
```
class TransactionalPolicy:
    def __init__(self, policy_data, **extra_data):
        self._data = {**policy_data, **extra_data}

    def change_in_policy(self, customer_id, **new_policy_data):
        self._data[customer_id].update(**new_policy_data)

    def __getitem__(self, customer_id):
        return self._data[customer_id]

    def __len__(self):
        return len(self._data)
```
### (3) Multiple inheritance in Python
Multiple inheritance is a perfectly valid solution when used correctly, and this oepns up new patterns and mixins.  
However, when it's not implemented correctly, it will multiply the problems.
- Method Resolution Order(MRO)
Python resolves the diamond problem by using an algorithm called C3 linearization or MRO, which defines a deterministic way in which methods are going to be called.  

ex1) multiple inheritance  
```
class BaseModule:
    module_name = "top"

    def __init__(self), module_name):
        self.name = module_name

    def __str__(self):
        return f"{self.module_name}:{self.name}"


class BaseModule1(BaseModule):
    module_name = "module-1"


class BaseModule2(BaseModule):
    module_name = "module-2"


class ContreteModuleA12(BaseModule1, BaseModule2):
    """Extend 1 & 2"""
```
```
>>> str(ConcreteModuleA12("test"))
'module-1:test'
```
```
>>> [cls.__name__ for cls in ConcreteModuleA12.mro()]
['ConcreteModuleA12', 'BaseModule2', 'BaseModule2', 'BaseModule', 'object']
```

- Mixins  
A mixin is a base class that encapsulates some common behavior with the goal of reusing code.  
The idea is to use mixin classes along with other ones, through multiple inheritance, so that the methods or properties used on the mixin will be available.  

ex2) mixins
```
class BaseTokenizer:
    def __init__(self, str_token):
        self.str_token = str_token

    def __iter__(self):
        yield from self.str_token.split("-")
```
```
>>> tk = BaseTokenizer("28a2320b-fd3f-4627-9792-a2b38e3c46b0")
>>> list(tk)
['28a2320b', 'fd3f', '4627', '9792', 'a2b38e3c46b0']
```
```
class UpperIterableMixin:
    def __iter__(self):
        return map(str.upper, super().__iter__())


class Tokenzer(UpperIterableMixin, BaseTokenizer):
    pass
```

## 3-6. Arguments in functions and methods
In Python , functions can be defined to receive arguments in several different ways, and these arguments can also be provided by callers in multiple ways.  

### (1) How function arguments work in Python
- How arguments are copied to functions  
The first rule in Python is that all arguments are passed by a value.  
However if we are passing mutable objects, and the body of the function modifies this, then, of course, we have side-effect that ehty will have been changed by the time the function returns.  
```
def function(argument):
    argument += " in function"
    print(argument)
```
```
>>> immutable = "hello"
>>> function(immutable)
hello in function
>>> immutable
'hello'
>>> mutable = list("hello")
>>> function(mutable)
['h', 'e', 'l', 'l', 'o', ' ', 'i', 'n', ' ', 'f', 'u', 'n', 'c', 't', 'i', 'o', 'n']
>>> mutable
['h', 'e', 'l', 'l', 'o', ' ', 'i', 'n', ' ', 'f', 'u', 'n', 'c', 't', 'i', 'o', 'n']
```

- Variable number of arguments  
For a variable number of positional arguments, **the star symbol (*)** is used, preceding the name of the variable that is **packing those arguments**.  
```
>>> def show(e, rest):
        print("Element: {0} - Rest: {1}".format(e, rest))
>>> first, *rest = [1, 2, 3, 4, 5]
>>> show(first, rest)
Element: 1 - Rest: [2, 3, 4, 5]
>>> *rest, last = range(6)
>>> show(last, rest)
Element: 5 - Rest: [0, 1, 2, 3, 4]
>>> first, *middle, last = range(6)
>>> first
0
>>> middle
[1, 2, 3, 4]
>>> last
5
>>> first, last, *empty = (1, 2)
>>> first
1
>>> last
2
>>> empty
[]
```
```
USERS = [(i, f"first_name_{i}", "last_name_{i}) for i in range(1000)]
class User:
    def __init__(self, user_id, first_name, last_name):
        self.user_id = user_id
        self.first_name = first_name
        self.last_name = last_name
def bad_users_from_rows(dbrows) -> list:
    """A bad case (non-pythonic) of creating ''User''s from DB rows."""
    return [User(row[0], row[1], row[2]) for row in dbrows]
def users_from_rows(dbrows) -> list:
    """Create ''User''s from DB rows."""
    return [
        User(user_id, first_name, last_name)
        for (user_id, first_name, last_name) in dbrows
    ]
```
There is a similar notation, with __two stars (**)__ for keyword arguments.  
If we have **a dictionary** and we pass it with a double star to a function, what it will do is **pick the keys as the name for the parameter, and pass the value for that key as the value for that parameter** in that function.
```
function(**{"key": "value"})
function(key="value")
```
Conversely, if we define a function with a parameter starting with two-star symbols, keyword-provided parameters will be packed into a dictionary.
```
>>> def function(**kwargs):
        print(kwargs)
>>> function(key="value")
{'key': 'value'}
```

### (2) The number of arguments in functions
Having functions or methods that take too many arguments is a sign of bad design.  
Alternatives:
- Reification: Creating a new object for all of those arguments that we are passing  
- making use of variable positional and keyword arguments

## 3-7. Final remarks on good practices for software design

### (1) Orthogonality in software
Changing a module, class, or function should have no impact on the outside world to that component that is being modify.  
ex1) passing functions by parameter
```
def calculate_price(base_price: float, tax: float, discount: float) -> float
    return (base_price * (1 + tax)) * (1 - discount)


def show_price(price: float) -> str:
    return "$ {0:,.2f}".format(price)


def str_final_price(
    base_price: float, tax: float, discount: float, fmt_function=str
) -> str:
    return fmt_function(calculate_price(base_price, tax, discount))
```
```
>>> str_final_price(10, 0.2, 0.5)
'0.6'
>>> str_final_price(1000, 0.2, 0)
'1200.0'
>>> str_final_price(1000, 0.2, 0.1, fmt_function=show_price)
'$ 1,080.00'
```

### (2) Structuring the code
A good code base will structure and arrange components by similarity.  
If multiple other parts of the code depend on definitions made on that file, this can be broken down into a package, and will maintain total compatibility.  
The idea would be to create a new directory with a `__init__.py` file on it.
